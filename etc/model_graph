digraph {
	graph [size="295.05,295.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	281470358086784 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	281470356349200 -> 281470358088144 [dir=none]
	281470358088144 [label="mat1
 (1, 2048)" fillcolor=orange]
	281470356349200 -> 281470358084224 [dir=none]
	281470358084224 [label="mat2
 (2048, 1000)" fillcolor=orange]
	281470356349200 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :      (1, 2048)
mat1_sym_strides:      (2048, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :   (2048, 1000)
mat2_sym_strides:      (1, 2048)"]
	281470356350016 -> 281470356349200
	281470358083744 [label="classifier.1.bias
 (1000)" fillcolor=lightblue]
	281470358083744 -> 281470356350016
	281470356350016 [label=AccumulateGrad]
	281470356349824 -> 281470356349200
	281470356349824 [label="ViewBackward0
-------------------------------
self_sym_sizes: (1, 2048, 1, 1)"]
	281470356349488 -> 281470356349824
	281470356349488 [label="MeanBackward1
------------------------------------------------------------
dim           : (18446744073709551615, 18446744073709551614)
keepdim       :                                         True
self_sym_numel:                                       100352
self_sym_sizes:                              (1, 2048, 7, 7)"]
	281470356350160 -> 281470356349488
	281470356350160 -> 281470401083920 [dir=none]
	281470401083920 [label="result
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356350160 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356350256 -> 281470356350160
	281470356350256 [label="AddBackward0
------------
alpha: 1"]
	281470356350352 -> 281470356350256
	281470356350352 -> 281470358088464 [dir=none]
	281470358088464 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356350352 -> 281470358083104 [dir=none]
	281470358083104 [label="result1
 (0)" fillcolor=orange]
	281470356350352 -> 281470358084304 [dir=none]
	281470358084304 [label="result2
 (0)" fillcolor=orange]
	281470356350352 -> 281470358104288 [dir=none]
	281470358104288 [label="running_mean
 (2048)" fillcolor=orange]
	281470356350352 -> 281470358104608 [dir=none]
	281470358104608 [label="running_var
 (2048)" fillcolor=orange]
	281470356350352 -> 281470356767504 [dir=none]
	281470356767504 [label="weight
 (2048)" fillcolor=orange]
	281470356350352 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356350496 -> 281470356350352
	281470356350496 -> 281470358088064 [dir=none]
	281470358088064 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356350496 -> 281470356767184 [dir=none]
	281470356767184 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	281470356350496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356350688 -> 281470356350496
	281470356350688 -> 281470358074400 [dir=none]
	281470358074400 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	281470356350688 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356350832 -> 281470356350688
	281470356350832 -> 281470358088784 [dir=none]
	281470358088784 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356350832 -> 281470357812656 [dir=none]
	281470357812656 [label="result1
 (0)" fillcolor=orange]
	281470356350832 -> 281470358082784 [dir=none]
	281470358082784 [label="result2
 (0)" fillcolor=orange]
	281470356350832 -> 281470358102368 [dir=none]
	281470358102368 [label="running_mean
 (512)" fillcolor=orange]
	281470356350832 -> 281470358102688 [dir=none]
	281470358102688 [label="running_var
 (512)" fillcolor=orange]
	281470356350832 -> 281470358175664 [dir=none]
	281470358175664 [label="weight
 (512)" fillcolor=orange]
	281470356350832 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356350928 -> 281470356350832
	281470356350928 -> 281470358088384 [dir=none]
	281470358088384 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356350928 -> 281470358175504 [dir=none]
	281470358175504 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	281470356350928 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356351120 -> 281470356350928
	281470356351120 -> 281470358083024 [dir=none]
	281470358083024 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	281470356351120 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356351264 -> 281470356351120
	281470356351264 -> 281470358088704 [dir=none]
	281470358088704 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356351264 -> 281470358081184 [dir=none]
	281470358081184 [label="result1
 (0)" fillcolor=orange]
	281470356351264 -> 281470358082464 [dir=none]
	281470358082464 [label="result2
 (0)" fillcolor=orange]
	281470356351264 -> 281470358100528 [dir=none]
	281470358100528 [label="running_mean
 (512)" fillcolor=orange]
	281470356351264 -> 281470358100848 [dir=none]
	281470358100848 [label="running_var
 (512)" fillcolor=orange]
	281470356351264 -> 281470358174944 [dir=none]
	281470358174944 [label="weight
 (512)" fillcolor=orange]
	281470356351264 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356351360 -> 281470356351264
	281470356351360 -> 281470358091984 [dir=none]
	281470358091984 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356351360 -> 281470358174624 [dir=none]
	281470358174624 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	281470356351360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356350304 -> 281470356351360
	281470356350304 -> 281470358084624 [dir=none]
	281470358084624 [label="result
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356350304 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356351648 -> 281470356350304
	281470356351648 [label="AddBackward0
------------
alpha: 1"]
	281470356351744 -> 281470356351648
	281470356351744 -> 281470358090384 [dir=none]
	281470358090384 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356351744 -> 281470358082704 [dir=none]
	281470358082704 [label="result1
 (0)" fillcolor=orange]
	281470356351744 -> 281470358080864 [dir=none]
	281470358080864 [label="result2
 (0)" fillcolor=orange]
	281470356351744 -> 281470358098688 [dir=none]
	281470358098688 [label="running_mean
 (2048)" fillcolor=orange]
	281470356351744 -> 281470358099008 [dir=none]
	281470358099008 [label="running_var
 (2048)" fillcolor=orange]
	281470356351744 -> 281470358174464 [dir=none]
	281470358174464 [label="weight
 (2048)" fillcolor=orange]
	281470356351744 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356351888 -> 281470356351744
	281470356351888 -> 281470358089984 [dir=none]
	281470358089984 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356351888 -> 281470358174304 [dir=none]
	281470358174304 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	281470356351888 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356352080 -> 281470356351888
	281470356352080 -> 281470358080464 [dir=none]
	281470358080464 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	281470356352080 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356352224 -> 281470356352080
	281470356352224 -> 281470358090704 [dir=none]
	281470358090704 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356352224 -> 281470358079264 [dir=none]
	281470358079264 [label="result1
 (0)" fillcolor=orange]
	281470356352224 -> 281470358082384 [dir=none]
	281470358082384 [label="result2
 (0)" fillcolor=orange]
	281470356352224 -> 281470358096768 [dir=none]
	281470358096768 [label="running_mean
 (512)" fillcolor=orange]
	281470356352224 -> 281470358097088 [dir=none]
	281470358097088 [label="running_var
 (512)" fillcolor=orange]
	281470356352224 -> 281470358173824 [dir=none]
	281470358173824 [label="weight
 (512)" fillcolor=orange]
	281470356352224 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356352320 -> 281470356352224
	281470356352320 -> 281470358090304 [dir=none]
	281470358090304 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356352320 -> 281470358173664 [dir=none]
	281470358173664 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	281470356352320 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356352512 -> 281470356352320
	281470356352512 -> 281470358081104 [dir=none]
	281470358081104 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	281470356352512 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356352656 -> 281470356352512
	281470356352656 -> 281470358091744 [dir=none]
	281470358091744 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356352656 -> 281470358078544 [dir=none]
	281470358078544 [label="result1
 (0)" fillcolor=orange]
	281470356352656 -> 281470358080784 [dir=none]
	281470358080784 [label="result2
 (0)" fillcolor=orange]
	281470356352656 -> 281470358095008 [dir=none]
	281470358095008 [label="running_mean
 (512)" fillcolor=orange]
	281470356352656 -> 281470358095328 [dir=none]
	281470358095328 [label="running_var
 (512)" fillcolor=orange]
	281470356352656 -> 281470358173264 [dir=none]
	281470358173264 [label="weight
 (512)" fillcolor=orange]
	281470356352656 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356352752 -> 281470356352656
	281470356352752 -> 281470358090624 [dir=none]
	281470358090624 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356352752 -> 281470358173104 [dir=none]
	281470358173104 [label="weight
 (512, 2048, 1, 1)" fillcolor=orange]
	281470356352752 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356351696 -> 281470356352752
	281470356351696 -> 281470358079184 [dir=none]
	281470358079184 [label="result
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356351696 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356353040 -> 281470356351696
	281470356353040 [label="AddBackward0
------------
alpha: 1"]
	281470356353136 -> 281470356353040
	281470356353136 -> 281470358092144 [dir=none]
	281470358092144 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356353136 -> 281470358088864 [dir=none]
	281470358088864 [label="result1
 (0)" fillcolor=orange]
	281470356353136 -> 281470358080544 [dir=none]
	281470358080544 [label="result2
 (0)" fillcolor=orange]
	281470356353136 -> 281470358091264 [dir=none]
	281470358091264 [label="running_mean
 (2048)" fillcolor=orange]
	281470356353136 -> 281470358091584 [dir=none]
	281470358091584 [label="running_var
 (2048)" fillcolor=orange]
	281470356353136 -> 281470358172704 [dir=none]
	281470358172704 [label="weight
 (2048)" fillcolor=orange]
	281470356353136 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356353280 -> 281470356353136
	281470356353280 -> 281470358092224 [dir=none]
	281470358092224 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356353280 -> 281470358172544 [dir=none]
	281470358172544 [label="weight
 (2048, 512, 1, 1)" fillcolor=orange]
	281470356353280 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356353472 -> 281470356353280
	281470356353472 -> 281470358090464 [dir=none]
	281470358090464 [label="result
 (1, 512, 7, 7)" fillcolor=orange]
	281470356353472 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356353616 -> 281470356353472
	281470356353616 -> 281470358092384 [dir=none]
	281470358092384 [label="input
 (1, 512, 7, 7)" fillcolor=orange]
	281470356353616 -> 281470358078624 [dir=none]
	281470358078624 [label="result1
 (0)" fillcolor=orange]
	281470356353616 -> 281470358078864 [dir=none]
	281470358078864 [label="result2
 (0)" fillcolor=orange]
	281470356353616 -> 281470358089344 [dir=none]
	281470358089344 [label="running_mean
 (512)" fillcolor=orange]
	281470356353616 -> 281470358089664 [dir=none]
	281470358089664 [label="running_var
 (512)" fillcolor=orange]
	281470356353616 -> 281470358172144 [dir=none]
	281470358172144 [label="weight
 (512)" fillcolor=orange]
	281470356353616 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356353712 -> 281470356353616
	281470356353712 -> 281470358092464 [dir=none]
	281470358092464 [label="input
 (1, 512, 14, 14)" fillcolor=orange]
	281470356353712 -> 281470358171984 [dir=none]
	281470358171984 [label="weight
 (512, 512, 3, 3)" fillcolor=orange]
	281470356353712 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470356353904 -> 281470356353712
	281470356353904 -> 281470358089824 [dir=none]
	281470358089824 [label="result
 (1, 512, 14, 14)" fillcolor=orange]
	281470356353904 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356354048 -> 281470356353904
	281470356354048 -> 281470358093744 [dir=none]
	281470358093744 [label="input
 (1, 512, 14, 14)" fillcolor=orange]
	281470356354048 -> 281470358078944 [dir=none]
	281470358078944 [label="result1
 (0)" fillcolor=orange]
	281470356354048 -> 281470358091904 [dir=none]
	281470358091904 [label="result2
 (0)" fillcolor=orange]
	281470356354048 -> 281470358087424 [dir=none]
	281470358087424 [label="running_mean
 (512)" fillcolor=orange]
	281470356354048 -> 281470358087744 [dir=none]
	281470358087744 [label="running_var
 (512)" fillcolor=orange]
	281470356354048 -> 281470358171504 [dir=none]
	281470358171504 [label="weight
 (512)" fillcolor=orange]
	281470356354048 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356354144 -> 281470356354048
	281470356354144 -> 281470358062080 [dir=none]
	281470358062080 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356354144 -> 281470358171344 [dir=none]
	281470358171344 [label="weight
 (512, 1024, 1, 1)" fillcolor=orange]
	281470356354144 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356354336 -> 281470356354144
	281470356354336 -> 281470358054256 [dir=none]
	281470358054256 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356354336 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356354480 -> 281470356354336
	281470356354480 [label="AddBackward0
------------
alpha: 1"]
	281470356354576 -> 281470356354480
	281470356354576 -> 281470358078704 [dir=none]
	281470358078704 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356354576 -> 281470358049216 [dir=none]
	281470358049216 [label="result1
 (0)" fillcolor=orange]
	281470356354576 -> 281470358060256 [dir=none]
	281470358060256 [label="result2
 (0)" fillcolor=orange]
	281470356354576 -> 281470358085504 [dir=none]
	281470358085504 [label="running_mean
 (1024)" fillcolor=orange]
	281470356354576 -> 281470358085824 [dir=none]
	281470358085824 [label="running_var
 (1024)" fillcolor=orange]
	281470356354576 -> 281470358170704 [dir=none]
	281470358170704 [label="weight
 (1024)" fillcolor=orange]
	281470356354576 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356354720 -> 281470356354576
	281470356354720 -> 281470358079984 [dir=none]
	281470358079984 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356354720 -> 281470358170464 [dir=none]
	281470358170464 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470356354720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356354912 -> 281470356354720
	281470356354912 -> 281470358060176 [dir=none]
	281470358060176 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470356354912 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356355056 -> 281470356354912
	281470356355056 -> 281470358061760 [dir=none]
	281470358061760 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356355056 -> 281470358059936 [dir=none]
	281470358059936 [label="result1
 (0)" fillcolor=orange]
	281470356355056 -> 281470358060576 [dir=none]
	281470358060576 [label="result2
 (0)" fillcolor=orange]
	281470356355056 -> 281470358083584 [dir=none]
	281470358083584 [label="running_mean
 (256)" fillcolor=orange]
	281470356355056 -> 281470358083904 [dir=none]
	281470358083904 [label="running_var
 (256)" fillcolor=orange]
	281470356355056 -> 281470358170064 [dir=none]
	281470358170064 [label="weight
 (256)" fillcolor=orange]
	281470356355056 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356355152 -> 281470356355056
	281470356355152 -> 281470358072480 [dir=none]
	281470358072480 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356355152 -> 281470358169824 [dir=none]
	281470358169824 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470356355152 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356355344 -> 281470356355152
	281470356355344 -> 281470358058656 [dir=none]
	281470358058656 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470356355344 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356355488 -> 281470356355344
	281470356355488 -> 281470358061680 [dir=none]
	281470358061680 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356355488 -> 281470358060496 [dir=none]
	281470358060496 [label="result1
 (0)" fillcolor=orange]
	281470356355488 -> 281470358058576 [dir=none]
	281470358058576 [label="result2
 (0)" fillcolor=orange]
	281470356355488 -> 281470358081744 [dir=none]
	281470358081744 [label="running_mean
 (256)" fillcolor=orange]
	281470356355488 -> 281470358082064 [dir=none]
	281470358082064 [label="running_var
 (256)" fillcolor=orange]
	281470356355488 -> 281470358169424 [dir=none]
	281470358169424 [label="weight
 (256)" fillcolor=orange]
	281470356355488 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356355632 -> 281470356355488
	281470356355632 -> 281470358063920 [dir=none]
	281470358063920 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356355632 -> 281470358169264 [dir=none]
	281470358169264 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	281470356355632 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356354528 -> 281470356355632
	281470356354528 -> 281470358057936 [dir=none]
	281470358057936 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356354528 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356355920 -> 281470356354528
	281470356355920 [label="AddBackward0
------------
alpha: 1"]
	281470356356016 -> 281470356355920
	281470356356016 -> 281470358062400 [dir=none]
	281470358062400 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356356016 -> 281470358058336 [dir=none]
	281470358058336 [label="result1
 (0)" fillcolor=orange]
	281470356356016 -> 281470358056736 [dir=none]
	281470358056736 [label="result2
 (0)" fillcolor=orange]
	281470356356016 -> 281470358079824 [dir=none]
	281470358079824 [label="running_mean
 (1024)" fillcolor=orange]
	281470356356016 -> 281470358080144 [dir=none]
	281470358080144 [label="running_var
 (1024)" fillcolor=orange]
	281470356356016 -> 281470358168864 [dir=none]
	281470358168864 [label="weight
 (1024)" fillcolor=orange]
	281470356356016 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356356160 -> 281470356356016
	281470356356160 -> 281470358062000 [dir=none]
	281470358062000 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356160 -> 281470358168624 [dir=none]
	281470358168624 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470356356160 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356356352 -> 281470356356160
	281470356356352 -> 281470358056656 [dir=none]
	281470358056656 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356352 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356356496 -> 281470356356352
	281470356356496 -> 281470358063600 [dir=none]
	281470358063600 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356496 -> 281470358058256 [dir=none]
	281470358058256 [label="result1
 (0)" fillcolor=orange]
	281470356356496 -> 281470358059856 [dir=none]
	281470358059856 [label="result2
 (0)" fillcolor=orange]
	281470356356496 -> 281470358077904 [dir=none]
	281470358077904 [label="running_mean
 (256)" fillcolor=orange]
	281470356356496 -> 281470358078224 [dir=none]
	281470358078224 [label="running_var
 (256)" fillcolor=orange]
	281470356356496 -> 281470358168224 [dir=none]
	281470358168224 [label="weight
 (256)" fillcolor=orange]
	281470356356496 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356356592 -> 281470356356496
	281470356356592 -> 281470358062320 [dir=none]
	281470358062320 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356592 -> 281470358167904 [dir=none]
	281470358167904 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470356356592 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356356784 -> 281470356356592
	281470356356784 -> 281470358056016 [dir=none]
	281470358056016 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356784 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356356928 -> 281470356356784
	281470356356928 -> 281470358063520 [dir=none]
	281470358063520 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356356928 -> 281470358058016 [dir=none]
	281470358058016 [label="result1
 (0)" fillcolor=orange]
	281470356356928 -> 281470358056416 [dir=none]
	281470358056416 [label="result2
 (0)" fillcolor=orange]
	281470356356928 -> 281470358076160 [dir=none]
	281470358076160 [label="running_mean
 (256)" fillcolor=orange]
	281470356356928 -> 281470358076400 [dir=none]
	281470358076400 [label="running_var
 (256)" fillcolor=orange]
	281470356356928 -> 281470358167424 [dir=none]
	281470358167424 [label="weight
 (256)" fillcolor=orange]
	281470356356928 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356357024 -> 281470356356928
	281470356357024 -> 281470358065840 [dir=none]
	281470358065840 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356357024 -> 281470358167264 [dir=none]
	281470358167264 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	281470356357024 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356355968 -> 281470356357024
	281470356355968 -> 281470358054816 [dir=none]
	281470358054816 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356355968 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357078272 -> 281470356355968
	281470357078272 [label="AddBackward0
------------
alpha: 1"]
	281470357078368 -> 281470357078272
	281470357078368 -> 281470358064240 [dir=none]
	281470358064240 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357078368 -> 281470358054736 [dir=none]
	281470358054736 [label="result1
 (0)" fillcolor=orange]
	281470357078368 -> 281470358054096 [dir=none]
	281470358054096 [label="result2
 (0)" fillcolor=orange]
	281470357078368 -> 281470358074240 [dir=none]
	281470358074240 [label="running_mean
 (1024)" fillcolor=orange]
	281470357078368 -> 281470358074560 [dir=none]
	281470358074560 [label="running_var
 (1024)" fillcolor=orange]
	281470357078368 -> 281470358166784 [dir=none]
	281470358166784 [label="weight
 (1024)" fillcolor=orange]
	281470357078368 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357078512 -> 281470357078368
	281470357078512 -> 281470358063840 [dir=none]
	281470358063840 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357078512 -> 281470358166624 [dir=none]
	281470358166624 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470357078512 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357078704 -> 281470357078512
	281470357078704 -> 281470358054496 [dir=none]
	281470358054496 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357078704 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357078848 -> 281470357078704
	281470357078848 -> 281470358065520 [dir=none]
	281470358065520 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357078848 -> 281470358056096 [dir=none]
	281470358056096 [label="result1
 (0)" fillcolor=orange]
	281470357078848 -> 281470358056336 [dir=none]
	281470358056336 [label="result2
 (0)" fillcolor=orange]
	281470357078848 -> 281470358072320 [dir=none]
	281470358072320 [label="running_mean
 (256)" fillcolor=orange]
	281470357078848 -> 281470358072640 [dir=none]
	281470358072640 [label="running_var
 (256)" fillcolor=orange]
	281470357078848 -> 281470358166144 [dir=none]
	281470358166144 [label="weight
 (256)" fillcolor=orange]
	281470357078848 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357078944 -> 281470357078848
	281470357078944 -> 281470358064160 [dir=none]
	281470358064160 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357078944 -> 281470358165984 [dir=none]
	281470358165984 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470357078944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357079136 -> 281470357078944
	281470357079136 -> 281470358052896 [dir=none]
	281470358052896 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357079136 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357079280 -> 281470357079136
	281470357079280 -> 281470358065440 [dir=none]
	281470358065440 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357079280 -> 281470358054416 [dir=none]
	281470358054416 [label="result1
 (0)" fillcolor=orange]
	281470357079280 -> 281470358052816 [dir=none]
	281470358052816 [label="result2
 (0)" fillcolor=orange]
	281470357079280 -> 281470358070400 [dir=none]
	281470358070400 [label="running_mean
 (256)" fillcolor=orange]
	281470357079280 -> 281470358070720 [dir=none]
	281470358070720 [label="running_var
 (256)" fillcolor=orange]
	281470357079280 -> 281470358165504 [dir=none]
	281470358165504 [label="weight
 (256)" fillcolor=orange]
	281470357079280 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357079376 -> 281470357079280
	281470357079376 -> 281470358067760 [dir=none]
	281470358067760 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357079376 -> 281470358165344 [dir=none]
	281470358165344 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	281470357079376 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357078320 -> 281470357079376
	281470357078320 -> 281470358052176 [dir=none]
	281470358052176 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357078320 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357079664 -> 281470357078320
	281470357079664 [label="AddBackward0
------------
alpha: 1"]
	281470357079760 -> 281470357079664
	281470357079760 -> 281470358066160 [dir=none]
	281470358066160 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357079760 -> 281470358052576 [dir=none]
	281470358052576 [label="result1
 (0)" fillcolor=orange]
	281470357079760 -> 281470358050976 [dir=none]
	281470358050976 [label="result2
 (0)" fillcolor=orange]
	281470357079760 -> 281470358068560 [dir=none]
	281470358068560 [label="running_mean
 (1024)" fillcolor=orange]
	281470357079760 -> 281470358068880 [dir=none]
	281470358068880 [label="running_var
 (1024)" fillcolor=orange]
	281470357079760 -> 281470358164864 [dir=none]
	281470358164864 [label="weight
 (1024)" fillcolor=orange]
	281470357079760 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357079952 -> 281470357079760
	281470357079952 -> 281470358065760 [dir=none]
	281470358065760 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357079952 -> 281470358164704 [dir=none]
	281470358164704 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470357079952 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357080144 -> 281470357079952
	281470357080144 -> 281470358050896 [dir=none]
	281470358050896 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357080144 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357080288 -> 281470357080144
	281470357080288 -> 281470358067440 [dir=none]
	281470358067440 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357080288 -> 281470358052496 [dir=none]
	281470358052496 [label="result1
 (0)" fillcolor=orange]
	281470357080288 -> 281470358054176 [dir=none]
	281470358054176 [label="result2
 (0)" fillcolor=orange]
	281470357080288 -> 281470358066720 [dir=none]
	281470358066720 [label="running_mean
 (256)" fillcolor=orange]
	281470357080288 -> 281470358067040 [dir=none]
	281470358067040 [label="running_var
 (256)" fillcolor=orange]
	281470357080288 -> 281470358164224 [dir=none]
	281470358164224 [label="weight
 (256)" fillcolor=orange]
	281470357080288 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357080432 -> 281470357080288
	281470357080432 -> 281470358066080 [dir=none]
	281470358066080 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357080432 -> 281470358164064 [dir=none]
	281470358164064 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470357080432 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357080624 -> 281470357080432
	281470357080624 -> 281470358050336 [dir=none]
	281470358050336 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357080624 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357080768 -> 281470357080624
	281470357080768 -> 281470358067360 [dir=none]
	281470358067360 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357080768 -> 281470358052256 [dir=none]
	281470358052256 [label="result1
 (0)" fillcolor=orange]
	281470357080768 -> 281470358050656 [dir=none]
	281470358050656 [label="result2
 (0)" fillcolor=orange]
	281470357080768 -> 281470358064800 [dir=none]
	281470358064800 [label="running_mean
 (256)" fillcolor=orange]
	281470357080768 -> 281470358065120 [dir=none]
	281470358065120 [label="running_var
 (256)" fillcolor=orange]
	281470357080768 -> 281470358163664 [dir=none]
	281470358163664 [label="weight
 (256)" fillcolor=orange]
	281470357080768 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357080912 -> 281470357080768
	281470357080912 -> 281470358069520 [dir=none]
	281470358069520 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357080912 -> 281470358163504 [dir=none]
	281470358163504 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	281470357080912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357079712 -> 281470357080912
	281470357079712 -> 281470358049136 [dir=none]
	281470358049136 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357079712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357081200 -> 281470357079712
	281470357081200 [label="AddBackward0
------------
alpha: 1"]
	281470357081296 -> 281470357081200
	281470357081296 -> 281470358068080 [dir=none]
	281470358068080 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357081296 -> 281470358049056 [dir=none]
	281470358049056 [label="result1
 (0)" fillcolor=orange]
	281470357081296 -> 281470358048416 [dir=none]
	281470358048416 [label="result2
 (0)" fillcolor=orange]
	281470357081296 -> 281470358062880 [dir=none]
	281470358062880 [label="running_mean
 (1024)" fillcolor=orange]
	281470357081296 -> 281470358063200 [dir=none]
	281470358063200 [label="running_var
 (1024)" fillcolor=orange]
	281470357081296 -> 281470358163024 [dir=none]
	281470358163024 [label="weight
 (1024)" fillcolor=orange]
	281470357081296 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357081488 -> 281470357081296
	281470357081488 -> 281470358067680 [dir=none]
	281470358067680 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357081488 -> 281470358162864 [dir=none]
	281470358162864 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470357081488 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357081680 -> 281470357081488
	281470357081680 -> 281470358048816 [dir=none]
	281470358048816 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357081680 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357081824 -> 281470357081680
	281470357081824 -> 281470358069280 [dir=none]
	281470358069280 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357081824 -> 281470358050416 [dir=none]
	281470358050416 [label="result1
 (0)" fillcolor=orange]
	281470357081824 -> 281470358050576 [dir=none]
	281470358050576 [label="result2
 (0)" fillcolor=orange]
	281470357081824 -> 281470358061200 [dir=none]
	281470358061200 [label="running_mean
 (256)" fillcolor=orange]
	281470357081824 -> 281470358061440 [dir=none]
	281470358061440 [label="running_var
 (256)" fillcolor=orange]
	281470357081824 -> 281470358162384 [dir=none]
	281470358162384 [label="weight
 (256)" fillcolor=orange]
	281470357081824 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356348912 -> 281470357081824
	281470356348912 -> 281470358068000 [dir=none]
	281470358068000 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470356348912 -> 281470358162224 [dir=none]
	281470358162224 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470356348912 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357082016 -> 281470356348912
	281470357082016 -> 281470358047216 [dir=none]
	281470358047216 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357082016 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357082160 -> 281470357082016
	281470357082160 -> 281470358069440 [dir=none]
	281470358069440 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357082160 -> 281470358048736 [dir=none]
	281470358048736 [label="result1
 (0)" fillcolor=orange]
	281470357082160 -> 281470358047136 [dir=none]
	281470358047136 [label="result2
 (0)" fillcolor=orange]
	281470357082160 -> 281470358059216 [dir=none]
	281470358059216 [label="running_mean
 (256)" fillcolor=orange]
	281470357082160 -> 281470358059536 [dir=none]
	281470358059536 [label="running_var
 (256)" fillcolor=orange]
	281470357082160 -> 281470358161744 [dir=none]
	281470358161744 [label="weight
 (256)" fillcolor=orange]
	281470357082160 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357082304 -> 281470357082160
	281470357082304 -> 281470358069200 [dir=none]
	281470358069200 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357082304 -> 281470358161584 [dir=none]
	281470358161584 [label="weight
 (256, 1024, 1, 1)" fillcolor=orange]
	281470357082304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357081248 -> 281470357082304
	281470357081248 -> 281470358046496 [dir=none]
	281470358046496 [label="result
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357081248 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357082592 -> 281470357081248
	281470357082592 [label="AddBackward0
------------
alpha: 1"]
	281470357082688 -> 281470357082592
	281470357082688 -> 281470358069760 [dir=none]
	281470358069760 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357082688 -> 281470358046896 [dir=none]
	281470358046896 [label="result1
 (0)" fillcolor=orange]
	281470357082688 -> 281470358045296 [dir=none]
	281470358045296 [label="result2
 (0)" fillcolor=orange]
	281470357082688 -> 281470358055376 [dir=none]
	281470358055376 [label="running_mean
 (1024)" fillcolor=orange]
	281470357082688 -> 281470358055696 [dir=none]
	281470358055696 [label="running_var
 (1024)" fillcolor=orange]
	281470357082688 -> 281470358161184 [dir=none]
	281470358161184 [label="weight
 (1024)" fillcolor=orange]
	281470357082688 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357082880 -> 281470357082688
	281470357082880 -> 281470358069840 [dir=none]
	281470358069840 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357082880 -> 281470358161024 [dir=none]
	281470358161024 [label="weight
 (1024, 256, 1, 1)" fillcolor=orange]
	281470357082880 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357083072 -> 281470357082880
	281470357083072 -> 281470358045216 [dir=none]
	281470358045216 [label="result
 (1, 256, 14, 14)" fillcolor=orange]
	281470357083072 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357083216 -> 281470357083072
	281470357083216 -> 281470358071040 [dir=none]
	281470358071040 [label="input
 (1, 256, 14, 14)" fillcolor=orange]
	281470357083216 -> 281470358046816 [dir=none]
	281470358046816 [label="result1
 (0)" fillcolor=orange]
	281470357083216 -> 281470358048496 [dir=none]
	281470358048496 [label="result2
 (0)" fillcolor=orange]
	281470357083216 -> 281470358053456 [dir=none]
	281470358053456 [label="running_mean
 (256)" fillcolor=orange]
	281470357083216 -> 281470358053776 [dir=none]
	281470358053776 [label="running_var
 (256)" fillcolor=orange]
	281470357083216 -> 281470358160544 [dir=none]
	281470358160544 [label="weight
 (256)" fillcolor=orange]
	281470357083216 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357083360 -> 281470357083216
	281470357083360 -> 281470358071120 [dir=none]
	281470358071120 [label="input
 (1, 256, 28, 28)" fillcolor=orange]
	281470357083360 -> 281470644350512 [dir=none]
	281470644350512 [label="weight
 (256, 256, 3, 3)" fillcolor=orange]
	281470357083360 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470357083552 -> 281470357083360
	281470357083552 -> 281470358044736 [dir=none]
	281470358044736 [label="result
 (1, 256, 28, 28)" fillcolor=orange]
	281470357083552 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357083696 -> 281470357083552
	281470357083696 -> 281470358071440 [dir=none]
	281470358071440 [label="input
 (1, 256, 28, 28)" fillcolor=orange]
	281470357083696 -> 281470358046576 [dir=none]
	281470358046576 [label="result1
 (0)" fillcolor=orange]
	281470357083696 -> 281470358044976 [dir=none]
	281470358044976 [label="result2
 (0)" fillcolor=orange]
	281470357083696 -> 281470358051536 [dir=none]
	281470358051536 [label="running_mean
 (256)" fillcolor=orange]
	281470357083696 -> 281470358051856 [dir=none]
	281470358051856 [label="running_var
 (256)" fillcolor=orange]
	281470357083696 -> 281470644352352 [dir=none]
	281470644352352 [label="weight
 (256)" fillcolor=orange]
	281470357083696 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357083840 -> 281470357083696
	281470357083840 -> 281470358073280 [dir=none]
	281470358073280 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357083840 -> 281470644344912 [dir=none]
	281470644344912 [label="weight
 (256, 512, 1, 1)" fillcolor=orange]
	281470357083840 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357084032 -> 281470357083840
	281470357084032 -> 281470358054896 [dir=none]
	281470358054896 [label="result
 (1, 512, 28, 28)" fillcolor=orange]
	281470357084032 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357084176 -> 281470357084032
	281470357084176 [label="AddBackward0
------------
alpha: 1"]
	281470357084272 -> 281470357084176
	281470357084272 -> 281470358071680 [dir=none]
	281470358071680 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357084272 -> 281470358044896 [dir=none]
	281470358044896 [label="result1
 (0)" fillcolor=orange]
	281470357084272 -> 281470358045696 [dir=none]
	281470358045696 [label="result2
 (0)" fillcolor=orange]
	281470357084272 -> 281470358049696 [dir=none]
	281470358049696 [label="running_mean
 (512)" fillcolor=orange]
	281470357084272 -> 281470358050016 [dir=none]
	281470358050016 [label="running_var
 (512)" fillcolor=orange]
	281470357084272 -> 281470644351792 [dir=none]
	281470644351792 [label="weight
 (512)" fillcolor=orange]
	281470357084272 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357084464 -> 281470357084272
	281470357084464 -> 281470358071760 [dir=none]
	281470358071760 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357084464 -> 281470358062160 [dir=none]
	281470358062160 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	281470357084464 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357084656 -> 281470357084464
	281470357084656 -> 281470358053296 [dir=none]
	281470358053296 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357084656 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357084800 -> 281470357084656
	281470357084800 -> 281470358072960 [dir=none]
	281470358072960 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357084800 -> 281470358044816 [dir=none]
	281470358044816 [label="result1
 (0)" fillcolor=orange]
	281470357084800 -> 281470358048576 [dir=none]
	281470358048576 [label="result2
 (0)" fillcolor=orange]
	281470357084800 -> 281470358047776 [dir=none]
	281470358047776 [label="running_mean
 (128)" fillcolor=orange]
	281470357084800 -> 281470358048096 [dir=none]
	281470358048096 [label="running_var
 (128)" fillcolor=orange]
	281470357084800 -> 281470644352032 [dir=none]
	281470644352032 [label="weight
 (128)" fillcolor=orange]
	281470357084800 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357084944 -> 281470357084800
	281470357084944 -> 281470358073040 [dir=none]
	281470358073040 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357084944 -> 281470644345792 [dir=none]
	281470644345792 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	281470357084944 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357085136 -> 281470357084944
	281470357085136 -> 281470358099168 [dir=none]
	281470358099168 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357085136 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357085280 -> 281470357085136
	281470357085280 -> 281470358073360 [dir=none]
	281470358073360 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357085280 -> 281470358104928 [dir=none]
	281470358104928 [label="result1
 (0)" fillcolor=orange]
	281470357085280 -> 281470358101008 [dir=none]
	281470358101008 [label="result2
 (0)" fillcolor=orange]
	281470357085280 -> 281470358045856 [dir=none]
	281470358045856 [label="running_mean
 (128)" fillcolor=orange]
	281470357085280 -> 281470358046176 [dir=none]
	281470358046176 [label="running_var
 (128)" fillcolor=orange]
	281470357085280 -> 281470644352512 [dir=none]
	281470644352512 [label="weight
 (128)" fillcolor=orange]
	281470357085280 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357085424 -> 281470357085280
	281470357085424 -> 281470358075200 [dir=none]
	281470358075200 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357085424 -> 281470644346272 [dir=none]
	281470644346272 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	281470357085424 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357084224 -> 281470357085424
	281470357084224 -> 281470358103648 [dir=none]
	281470358103648 [label="result
 (1, 512, 28, 28)" fillcolor=orange]
	281470357084224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357085712 -> 281470357084224
	281470357085712 [label="AddBackward0
------------
alpha: 1"]
	281470357085808 -> 281470357085712
	281470357085808 -> 281470358073600 [dir=none]
	281470358073600 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357085808 -> 281470358103328 [dir=none]
	281470358103328 [label="result1
 (0)" fillcolor=orange]
	281470357085808 -> 281470358105008 [dir=none]
	281470358105008 [label="result2
 (0)" fillcolor=orange]
	281470357085808 -> 281470358027568 [dir=none]
	281470358027568 [label="running_mean
 (512)" fillcolor=orange]
	281470357085808 -> 281470358027888 [dir=none]
	281470358027888 [label="running_var
 (512)" fillcolor=orange]
	281470357085808 -> 281470644352832 [dir=none]
	281470644352832 [label="weight
 (512)" fillcolor=orange]
	281470357085808 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357086000 -> 281470357085808
	281470357086000 -> 281470358073680 [dir=none]
	281470358073680 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086000 -> 281470644346512 [dir=none]
	281470644346512 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	281470357086000 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357086192 -> 281470357086000
	281470357086192 -> 281470358103008 [dir=none]
	281470358103008 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086192 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357086336 -> 281470357086192
	281470357086336 -> 281470358074880 [dir=none]
	281470358074880 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086336 -> 281470358095488 [dir=none]
	281470358095488 [label="result1
 (0)" fillcolor=orange]
	281470357086336 -> 281470358103408 [dir=none]
	281470358103408 [label="result2
 (0)" fillcolor=orange]
	281470357086336 -> 281470358025648 [dir=none]
	281470358025648 [label="running_mean
 (128)" fillcolor=orange]
	281470357086336 -> 281470358025968 [dir=none]
	281470358025968 [label="running_var
 (128)" fillcolor=orange]
	281470357086336 -> 281470644346912 [dir=none]
	281470644346912 [label="weight
 (128)" fillcolor=orange]
	281470357086336 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357086480 -> 281470357086336
	281470357086480 -> 281470358074960 [dir=none]
	281470358074960 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086480 -> 281470644346672 [dir=none]
	281470644346672 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	281470357086480 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357086672 -> 281470357086480
	281470357086672 -> 281470358101808 [dir=none]
	281470358101808 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086672 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357086816 -> 281470357086672
	281470357086816 -> 281470358075280 [dir=none]
	281470358075280 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357086816 -> 281470358103728 [dir=none]
	281470358103728 [label="result1
 (0)" fillcolor=orange]
	281470357086816 -> 281470358101728 [dir=none]
	281470358101728 [label="result2
 (0)" fillcolor=orange]
	281470357086816 -> 281470358023728 [dir=none]
	281470358023728 [label="running_mean
 (128)" fillcolor=orange]
	281470357086816 -> 281470358024048 [dir=none]
	281470358024048 [label="running_var
 (128)" fillcolor=orange]
	281470357086816 -> 281470644347072 [dir=none]
	281470644347072 [label="weight
 (128)" fillcolor=orange]
	281470357086816 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357086960 -> 281470357086816
	281470357086960 -> 281470358076960 [dir=none]
	281470358076960 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357086960 -> 281470644353552 [dir=none]
	281470644353552 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	281470357086960 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357085760 -> 281470357086960
	281470357085760 -> 281470358101168 [dir=none]
	281470358101168 [label="result
 (1, 512, 28, 28)" fillcolor=orange]
	281470357085760 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357087248 -> 281470357085760
	281470357087248 [label="AddBackward0
------------
alpha: 1"]
	281470357087344 -> 281470357087248
	281470357087344 -> 281470358075520 [dir=none]
	281470358075520 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357087344 -> 281470358103088 [dir=none]
	281470358103088 [label="result1
 (0)" fillcolor=orange]
	281470357087344 -> 281470358101568 [dir=none]
	281470358101568 [label="result2
 (0)" fillcolor=orange]
	281470357087344 -> 281470358021808 [dir=none]
	281470358021808 [label="running_mean
 (512)" fillcolor=orange]
	281470357087344 -> 281470358022128 [dir=none]
	281470358022128 [label="running_var
 (512)" fillcolor=orange]
	281470357087344 -> 281470644347312 [dir=none]
	281470644347312 [label="weight
 (512)" fillcolor=orange]
	281470357087344 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357087536 -> 281470357087344
	281470357087536 -> 281470358075600 [dir=none]
	281470358075600 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357087536 -> 281470644353792 [dir=none]
	281470644353792 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	281470357087536 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357087728 -> 281470357087536
	281470357087728 -> 281470358099968 [dir=none]
	281470358099968 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357087728 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357087872 -> 281470357087728
	281470357087872 -> 281470358076640 [dir=none]
	281470358076640 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357087872 -> 281470358101488 [dir=none]
	281470358101488 [label="result1
 (0)" fillcolor=orange]
	281470357087872 -> 281470358099888 [dir=none]
	281470358099888 [label="result2
 (0)" fillcolor=orange]
	281470357087872 -> 281470358019888 [dir=none]
	281470358019888 [label="running_mean
 (128)" fillcolor=orange]
	281470357087872 -> 281470358020208 [dir=none]
	281470358020208 [label="running_var
 (128)" fillcolor=orange]
	281470357087872 -> 281470644354032 [dir=none]
	281470644354032 [label="weight
 (128)" fillcolor=orange]
	281470357087872 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357088016 -> 281470357087872
	281470357088016 -> 281470358076720 [dir=none]
	281470358076720 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357088016 -> 281470644354112 [dir=none]
	281470644354112 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	281470357088016 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357088208 -> 281470357088016
	281470357088208 -> 281470358099328 [dir=none]
	281470358099328 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357088208 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357088352 -> 281470357088208
	281470357088352 -> 281470358077360 [dir=none]
	281470358077360 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357088352 -> 281470358101248 [dir=none]
	281470358101248 [label="result1
 (0)" fillcolor=orange]
	281470357088352 -> 281470358099648 [dir=none]
	281470358099648 [label="result2
 (0)" fillcolor=orange]
	281470357088352 -> 281470358017968 [dir=none]
	281470358017968 [label="running_mean
 (128)" fillcolor=orange]
	281470357088352 -> 281470358018288 [dir=none]
	281470358018288 [label="running_var
 (128)" fillcolor=orange]
	281470357088352 -> 281470644354352 [dir=none]
	281470644354352 [label="weight
 (128)" fillcolor=orange]
	281470357088352 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357088496 -> 281470357088352
	281470357088496 -> 281470358077040 [dir=none]
	281470358077040 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357088496 -> 281470644354432 [dir=none]
	281470644354432 [label="weight
 (128, 512, 1, 1)" fillcolor=orange]
	281470357088496 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357087296 -> 281470357088496
	281470357087296 -> 281470358098128 [dir=none]
	281470358098128 [label="result
 (1, 512, 28, 28)" fillcolor=orange]
	281470357087296 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357088784 -> 281470357087296
	281470357088784 [label="AddBackward0
------------
alpha: 1"]
	281470357088880 -> 281470357088784
	281470357088880 -> 281470358076800 [dir=none]
	281470358076800 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357088880 -> 281470358099568 [dir=none]
	281470358099568 [label="result1
 (0)" fillcolor=orange]
	281470357088880 -> 281470358098048 [dir=none]
	281470358098048 [label="result2
 (0)" fillcolor=orange]
	281470357088880 -> 281470358014128 [dir=none]
	281470358014128 [label="running_mean
 (512)" fillcolor=orange]
	281470357088880 -> 281470358014448 [dir=none]
	281470358014448 [label="running_var
 (512)" fillcolor=orange]
	281470357088880 -> 281470644338832 [dir=none]
	281470644338832 [label="weight
 (512)" fillcolor=orange]
	281470357088880 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357089072 -> 281470357088880
	281470357089072 -> 281470358077280 [dir=none]
	281470358077280 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357089072 -> 281470644348352 [dir=none]
	281470644348352 [label="weight
 (512, 128, 1, 1)" fillcolor=orange]
	281470357089072 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357089264 -> 281470357089072
	281470357089264 -> 281470358097408 [dir=none]
	281470358097408 [label="result
 (1, 128, 28, 28)" fillcolor=orange]
	281470357089264 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357089408 -> 281470357089264
	281470357089408 -> 281470586512752 [dir=none]
	281470586512752 [label="input
 (1, 128, 28, 28)" fillcolor=orange]
	281470357089408 -> 281470358099408 [dir=none]
	281470358099408 [label="result1
 (0)" fillcolor=orange]
	281470357089408 -> 281470358097808 [dir=none]
	281470358097808 [label="result2
 (0)" fillcolor=orange]
	281470357089408 -> 281470358012208 [dir=none]
	281470358012208 [label="running_mean
 (128)" fillcolor=orange]
	281470357089408 -> 281470358012528 [dir=none]
	281470358012528 [label="running_var
 (128)" fillcolor=orange]
	281470357089408 -> 281470644354832 [dir=none]
	281470644354832 [label="weight
 (128)" fillcolor=orange]
	281470357089408 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357089552 -> 281470357089408
	281470357089552 -> 281470358066880 [dir=none]
	281470358066880 [label="input
 (1, 128, 56, 56)" fillcolor=orange]
	281470357089552 -> 281470644348512 [dir=none]
	281470644348512 [label="weight
 (128, 128, 3, 3)" fillcolor=orange]
	281470357089552 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470357089744 -> 281470357089552
	281470357089744 -> 281470358096208 [dir=none]
	281470358096208 [label="result
 (1, 128, 56, 56)" fillcolor=orange]
	281470357089744 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357089888 -> 281470357089744
	281470357089888 -> 281470586518832 [dir=none]
	281470586518832 [label="input
 (1, 128, 56, 56)" fillcolor=orange]
	281470357089888 -> 281470358097728 [dir=none]
	281470358097728 [label="result1
 (0)" fillcolor=orange]
	281470357089888 -> 281470358096128 [dir=none]
	281470358096128 [label="result2
 (0)" fillcolor=orange]
	281470357089888 -> 281470358010224 [dir=none]
	281470358010224 [label="running_mean
 (128)" fillcolor=orange]
	281470357089888 -> 281470358010544 [dir=none]
	281470358010544 [label="running_var
 (128)" fillcolor=orange]
	281470357089888 -> 281470644348672 [dir=none]
	281470644348672 [label="weight
 (128)" fillcolor=orange]
	281470357089888 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357090032 -> 281470357089888
	281470357090032 -> 281470357807696 [dir=none]
	281470357807696 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357090032 -> 281470644348752 [dir=none]
	281470644348752 [label="weight
 (128, 256, 1, 1)" fillcolor=orange]
	281470357090032 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357090224 -> 281470357090032
	281470357090224 -> 281470358095568 [dir=none]
	281470358095568 [label="result
 (1, 256, 56, 56)" fillcolor=orange]
	281470357090224 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357090368 -> 281470357090224
	281470357090368 [label="AddBackward0
------------
alpha: 1"]
	281470357090464 -> 281470357090368
	281470357090464 -> 281470386876112 [dir=none]
	281470386876112 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357090464 -> 281470358097488 [dir=none]
	281470358097488 [label="result1
 (0)" fillcolor=orange]
	281470357090464 -> 281470358095888 [dir=none]
	281470358095888 [label="result2
 (0)" fillcolor=orange]
	281470357090464 -> 281470358008304 [dir=none]
	281470358008304 [label="running_mean
 (256)" fillcolor=orange]
	281470357090464 -> 281470358008624 [dir=none]
	281470358008624 [label="running_var
 (256)" fillcolor=orange]
	281470357090464 -> 281470644340192 [dir=none]
	281470644340192 [label="weight
 (256)" fillcolor=orange]
	281470357090464 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357090656 -> 281470357090464
	281470357090656 -> 281470357370048 [dir=none]
	281470357370048 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357090656 -> 281470644348912 [dir=none]
	281470644348912 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	281470357090656 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357090848 -> 281470357090656
	281470357090848 -> 281470358094448 [dir=none]
	281470358094448 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357090848 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357090992 -> 281470357090848
	281470357090992 -> 281470357807376 [dir=none]
	281470357807376 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357090992 -> 281470358100368 [dir=none]
	281470358100368 [label="result1
 (0)" fillcolor=orange]
	281470357090992 -> 281470358094368 [dir=none]
	281470358094368 [label="result2
 (0)" fillcolor=orange]
	281470357090992 -> 281470358006384 [dir=none]
	281470358006384 [label="running_mean
 (64)" fillcolor=orange]
	281470357090992 -> 281470358006704 [dir=none]
	281470358006704 [label="running_var
 (64)" fillcolor=orange]
	281470357090992 -> 281470644349232 [dir=none]
	281470644349232 [label="weight
 (64)" fillcolor=orange]
	281470357090992 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357091136 -> 281470357090992
	281470357091136 -> 281470357807456 [dir=none]
	281470357807456 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357091136 -> 281470644340512 [dir=none]
	281470644340512 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	281470357091136 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357091376 -> 281470357091136
	281470357091376 -> 281470358094128 [dir=none]
	281470358094128 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357091376 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357091520 -> 281470357091376
	281470357091520 -> 281470357807776 [dir=none]
	281470357807776 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357091520 -> 281470358094048 [dir=none]
	281470358094048 [label="result1
 (0)" fillcolor=orange]
	281470357091520 -> 281470358095808 [dir=none]
	281470358095808 [label="result2
 (0)" fillcolor=orange]
	281470357091520 -> 281470358004464 [dir=none]
	281470358004464 [label="running_mean
 (64)" fillcolor=orange]
	281470357091520 -> 281470358004784 [dir=none]
	281470358004784 [label="running_var
 (64)" fillcolor=orange]
	281470357091520 -> 281470644340752 [dir=none]
	281470644340752 [label="weight
 (64)" fillcolor=orange]
	281470357091520 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357091664 -> 281470357091520
	281470357091664 -> 281470357809616 [dir=none]
	281470357809616 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357091664 -> 281470644349552 [dir=none]
	281470644349552 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	281470357091664 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357090416 -> 281470357091664
	281470357090416 -> 281470358095648 [dir=none]
	281470358095648 [label="result
 (1, 256, 56, 56)" fillcolor=orange]
	281470357090416 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357091952 -> 281470357090416
	281470357091952 [label="AddBackward0
------------
alpha: 1"]
	281470357092048 -> 281470357091952
	281470357092048 -> 281470357808016 [dir=none]
	281470357808016 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357092048 -> 281470358094208 [dir=none]
	281470358094208 [label="result1
 (0)" fillcolor=orange]
	281470357092048 -> 281470358102848 [dir=none]
	281470358102848 [label="result2
 (0)" fillcolor=orange]
	281470357092048 -> 281470358002624 [dir=none]
	281470358002624 [label="running_mean
 (256)" fillcolor=orange]
	281470357092048 -> 281470358002944 [dir=none]
	281470358002944 [label="running_var
 (256)" fillcolor=orange]
	281470357092048 -> 281470644349792 [dir=none]
	281470644349792 [label="weight
 (256)" fillcolor=orange]
	281470357092048 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357092240 -> 281470357092048
	281470357092240 -> 281470357808096 [dir=none]
	281470357808096 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357092240 -> 281470644340992 [dir=none]
	281470644340992 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	281470357092240 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357092432 -> 281470357092240
	281470357092432 -> 281470356768144 [dir=none]
	281470356768144 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357092432 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357092576 -> 281470357092432
	281470357092576 -> 281470357808336 [dir=none]
	281470357808336 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357092576 -> 281470356782784 [dir=none]
	281470356782784 [label="result1
 (0)" fillcolor=orange]
	281470357092576 -> 281470356768944 [dir=none]
	281470356768944 [label="result2
 (0)" fillcolor=orange]
	281470357092576 -> 281470358000784 [dir=none]
	281470358000784 [label="running_mean
 (64)" fillcolor=orange]
	281470357092576 -> 281470358001024 [dir=none]
	281470358001024 [label="running_var
 (64)" fillcolor=orange]
	281470357092576 -> 281470358065920 [dir=none]
	281470358065920 [label="weight
 (64)" fillcolor=orange]
	281470357092576 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357092720 -> 281470357092576
	281470357092720 -> 281470357808416 [dir=none]
	281470357808416 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357092720 -> 281470358091104 [dir=none]
	281470358091104 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	281470357092720 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357092912 -> 281470357092720
	281470357092912 -> 281470356782864 [dir=none]
	281470356782864 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357092912 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357093056 -> 281470357092912
	281470357093056 -> 281470357810336 [dir=none]
	281470357810336 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357093056 -> 281470356782464 [dir=none]
	281470356782464 [label="result1
 (0)" fillcolor=orange]
	281470357093056 -> 281470356782944 [dir=none]
	281470356782944 [label="result2
 (0)" fillcolor=orange]
	281470357093056 -> 281470357998864 [dir=none]
	281470357998864 [label="running_mean
 (64)" fillcolor=orange]
	281470357093056 -> 281470357999184 [dir=none]
	281470357999184 [label="running_var
 (64)" fillcolor=orange]
	281470357093056 -> 281470644350352 [dir=none]
	281470644350352 [label="weight
 (64)" fillcolor=orange]
	281470357093056 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357093200 -> 281470357093056
	281470357093200 -> 281470357809696 [dir=none]
	281470357809696 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357093200 -> 281470644341552 [dir=none]
	281470644341552 [label="weight
 (64, 256, 1, 1)" fillcolor=orange]
	281470357093200 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357092000 -> 281470357093200
	281470357092000 -> 281470356782624 [dir=none]
	281470356782624 [label="result
 (1, 256, 56, 56)" fillcolor=orange]
	281470357092000 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357093488 -> 281470357092000
	281470357093488 [label="AddBackward0
------------
alpha: 1"]
	281470357093584 -> 281470357093488
	281470357093584 -> 281470357810256 [dir=none]
	281470357810256 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357093584 -> 281470356782544 [dir=none]
	281470356782544 [label="result1
 (0)" fillcolor=orange]
	281470357093584 -> 281470356783024 [dir=none]
	281470356783024 [label="result2
 (0)" fillcolor=orange]
	281470357093584 -> 281470357814736 [dir=none]
	281470357814736 [label="running_mean
 (256)" fillcolor=orange]
	281470357093584 -> 281470357815056 [dir=none]
	281470357815056 [label="running_var
 (256)" fillcolor=orange]
	281470357093584 -> 281470644380240 [dir=none]
	281470644380240 [label="weight
 (256)" fillcolor=orange]
	281470357093584 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357093776 -> 281470357093584
	281470357093776 -> 281470357811936 [dir=none]
	281470357811936 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357093776 -> 281470644373280 [dir=none]
	281470644373280 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	281470357093776 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357093968 -> 281470357093776
	281470357093968 -> 281470356782224 [dir=none]
	281470356782224 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357093968 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470357094112 -> 281470357093968
	281470357094112 -> 281470357811616 [dir=none]
	281470357811616 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357094112 -> 281470356781984 [dir=none]
	281470356781984 [label="result1
 (0)" fillcolor=orange]
	281470357094112 -> 281470356782304 [dir=none]
	281470356782304 [label="result2
 (0)" fillcolor=orange]
	281470357094112 -> 281470357812816 [dir=none]
	281470357812816 [label="running_mean
 (64)" fillcolor=orange]
	281470357094112 -> 281470357813136 [dir=none]
	281470357813136 [label="running_var
 (64)" fillcolor=orange]
	281470357094112 -> 281470644374960 [dir=none]
	281470644374960 [label="weight
 (64)" fillcolor=orange]
	281470357094112 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357094256 -> 281470357094112
	281470357094256 -> 281470357809936 [dir=none]
	281470357809936 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357094256 -> 281470644375120 [dir=none]
	281470644375120 [label="weight
 (64, 64, 3, 3)" fillcolor=orange]
	281470357094256 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (1, 1)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470357094352 -> 281470357094256
	281470357094352 -> 281470356782064 [dir=none]
	281470356782064 [label="result
 (1, 64, 56, 56)" fillcolor=orange]
	281470357094352 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356979968 -> 281470357094352
	281470356979968 -> 281470357810016 [dir=none]
	281470357810016 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470356979968 -> 281470356781744 [dir=none]
	281470356781744 [label="result1
 (0)" fillcolor=orange]
	281470356979968 -> 281470356782704 [dir=none]
	281470356782704 [label="result2
 (0)" fillcolor=orange]
	281470356979968 -> 281470357810896 [dir=none]
	281470357810896 [label="running_mean
 (64)" fillcolor=orange]
	281470356979968 -> 281470357811216 [dir=none]
	281470357811216 [label="running_var
 (64)" fillcolor=orange]
	281470356979968 -> 281470358049536 [dir=none]
	281470358049536 [label="weight
 (64)" fillcolor=orange]
	281470356979968 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356980112 -> 281470356979968
	281470356980112 -> 281470396262384 [dir=none]
	281470396262384 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470356980112 -> 281470358085664 [dir=none]
	281470358085664 [label="weight
 (64, 64, 1, 1)" fillcolor=orange]
	281470356980112 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356980304 -> 281470356980112
	281470356980304 -> 281470356781824 [dir=none]
	281470356781824 [label="result1
 (1, 64, 56, 56)" fillcolor=orange]
	281470356980304 -> 281470378567104 [dir=none]
	281470378567104 [label="self
 (1, 64, 112, 112)" fillcolor=orange]
	281470356980304 [label="MaxPool2DWithIndicesBackward0
-----------------------------
ceil_mode  :          False
dilation   :         (1, 1)
kernel_size:         (3, 3)
padding    :         (1, 1)
result1    : [saved tensor]
self       : [saved tensor]
stride     :         (2, 2)"]
	281470356980448 -> 281470356980304
	281470356980448 -> 281470356781584 [dir=none]
	281470356781584 [label="result
 (1, 64, 112, 112)" fillcolor=orange]
	281470356980448 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	281470356980592 -> 281470356980448
	281470356980592 -> 281472933636000 [dir=none]
	281472933636000 [label="input
 (1, 64, 112, 112)" fillcolor=orange]
	281470356980592 -> 281470356782144 [dir=none]
	281470356782144 [label="result1
 (0)" fillcolor=orange]
	281470356980592 -> 281470356781904 [dir=none]
	281470356781904 [label="result2
 (0)" fillcolor=orange]
	281470356980592 -> 281470357808976 [dir=none]
	281470357808976 [label="running_mean
 (64)" fillcolor=orange]
	281470356980592 -> 281470357809296 [dir=none]
	281470357809296 [label="running_var
 (64)" fillcolor=orange]
	281470356980592 -> 281470644375680 [dir=none]
	281470644375680 [label="weight
 (64)" fillcolor=orange]
	281470356980592 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356980736 -> 281470356980592
	281470356980736 -> 281470588958048 [dir=none]
	281470588958048 [label="input
 (1, 3, 224, 224)" fillcolor=orange]
	281470356980736 -> 281470358104128 [dir=none]
	281470358104128 [label="weight
 (64, 3, 7, 7)" fillcolor=orange]
	281470356980736 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (3, 3)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470356980928 -> 281470356980736
	281470358104128 [label="resnet.embedder.embedder.convolution.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	281470358104128 -> 281470356980928
	281470356980928 [label=AccumulateGrad]
	281470356980640 -> 281470356980592
	281470644375680 [label="resnet.embedder.embedder.normalization.weight
 (64)" fillcolor=lightblue]
	281470644375680 -> 281470356980640
	281470356980640 [label=AccumulateGrad]
	281470356980352 -> 281470356980592
	281470356780384 [label="resnet.embedder.embedder.normalization.bias
 (64)" fillcolor=lightblue]
	281470356780384 -> 281470356980352
	281470356980352 [label=AccumulateGrad]
	281470356980256 -> 281470356980112
	281470358085664 [label="resnet.encoder.stages.0.layers.0.layer.0.convolution.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	281470358085664 -> 281470356980256
	281470356980256 [label=AccumulateGrad]
	281470356980016 -> 281470356979968
	281470358049536 [label="resnet.encoder.stages.0.layers.0.layer.0.normalization.weight
 (64)" fillcolor=lightblue]
	281470358049536 -> 281470356980016
	281470356980016 [label=AccumulateGrad]
	281470356979872 -> 281470356979968
	281470358082224 [label="resnet.encoder.stages.0.layers.0.layer.0.normalization.bias
 (64)" fillcolor=lightblue]
	281470358082224 -> 281470356979872
	281470356979872 [label=AccumulateGrad]
	281470356979824 -> 281470357094256
	281470644375120 [label="resnet.encoder.stages.0.layers.0.layer.1.convolution.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	281470644375120 -> 281470356979824
	281470356979824 [label=AccumulateGrad]
	281470357094160 -> 281470357094112
	281470644374960 [label="resnet.encoder.stages.0.layers.0.layer.1.normalization.weight
 (64)" fillcolor=lightblue]
	281470644374960 -> 281470357094160
	281470357094160 [label=AccumulateGrad]
	281470357094016 -> 281470357094112
	281470644375440 [label="resnet.encoder.stages.0.layers.0.layer.1.normalization.bias
 (64)" fillcolor=lightblue]
	281470644375440 -> 281470357094016
	281470357094016 [label=AccumulateGrad]
	281470357093920 -> 281470357093776
	281470644373280 [label="resnet.encoder.stages.0.layers.0.layer.2.convolution.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	281470644373280 -> 281470357093920
	281470357093920 [label=AccumulateGrad]
	281470357093680 -> 281470357093584
	281470644380240 [label="resnet.encoder.stages.0.layers.0.layer.2.normalization.weight
 (256)" fillcolor=lightblue]
	281470644380240 -> 281470357093680
	281470357093680 [label=AccumulateGrad]
	281470357093632 -> 281470357093584
	281470644374800 [label="resnet.encoder.stages.0.layers.0.layer.2.normalization.bias
 (256)" fillcolor=lightblue]
	281470644374800 -> 281470357093632
	281470357093632 [label=AccumulateGrad]
	281470357093536 -> 281470357093488
	281470357093536 -> 281470357813536 [dir=none]
	281470357813536 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357093536 -> 281470356781504 [dir=none]
	281470356781504 [label="result1
 (0)" fillcolor=orange]
	281470357093536 -> 281470356781264 [dir=none]
	281470356781264 [label="result2
 (0)" fillcolor=orange]
	281470357093536 -> 281470357996944 [dir=none]
	281470357996944 [label="running_mean
 (256)" fillcolor=orange]
	281470357093536 -> 281470357997264 [dir=none]
	281470357997264 [label="running_var
 (256)" fillcolor=orange]
	281470357093536 -> 281470358165424 [dir=none]
	281470358165424 [label="weight
 (256)" fillcolor=orange]
	281470357093536 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357094304 -> 281470357093536
	281470357094304 -> 281470396262384 [dir=none]
	281470396262384 [label="input
 (1, 64, 56, 56)" fillcolor=orange]
	281470357094304 -> 281470358095168 [dir=none]
	281470358095168 [label="weight
 (256, 64, 1, 1)" fillcolor=orange]
	281470357094304 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (1, 1)
transposed        :          False
weight            : [saved tensor]"]
	281470356980304 -> 281470357094304
	281470356980160 -> 281470357094304
	281470358095168 [label="resnet.encoder.stages.0.layers.0.shortcut.convolution.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	281470358095168 -> 281470356980160
	281470356980160 [label=AccumulateGrad]
	281470357093872 -> 281470357093536
	281470358165424 [label="resnet.encoder.stages.0.layers.0.shortcut.normalization.weight
 (256)" fillcolor=lightblue]
	281470358165424 -> 281470357093872
	281470357093872 [label=AccumulateGrad]
	281470357093824 -> 281470357093536
	281470357147776 [label="resnet.encoder.stages.0.layers.0.shortcut.normalization.bias
 (256)" fillcolor=lightblue]
	281470357147776 -> 281470357093824
	281470357093824 [label=AccumulateGrad]
	281470357093392 -> 281470357093200
	281470644341552 [label="resnet.encoder.stages.0.layers.1.layer.0.convolution.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	281470644341552 -> 281470357093392
	281470357093392 [label=AccumulateGrad]
	281470357093104 -> 281470357093056
	281470644350352 [label="resnet.encoder.stages.0.layers.1.layer.0.normalization.weight
 (64)" fillcolor=lightblue]
	281470644350352 -> 281470357093104
	281470357093104 [label=AccumulateGrad]
	281470357092960 -> 281470357093056
	281470644341632 [label="resnet.encoder.stages.0.layers.1.layer.0.normalization.bias
 (64)" fillcolor=lightblue]
	281470644341632 -> 281470357092960
	281470357092960 [label=AccumulateGrad]
	281470357092864 -> 281470357092720
	281470358091104 [label="resnet.encoder.stages.0.layers.1.layer.1.convolution.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	281470358091104 -> 281470357092864
	281470357092864 [label=AccumulateGrad]
	281470357092624 -> 281470357092576
	281470358065920 [label="resnet.encoder.stages.0.layers.1.layer.1.normalization.weight
 (64)" fillcolor=lightblue]
	281470358065920 -> 281470357092624
	281470357092624 [label=AccumulateGrad]
	281470357092480 -> 281470357092576
	281470358066240 [label="resnet.encoder.stages.0.layers.1.layer.1.normalization.bias
 (64)" fillcolor=lightblue]
	281470358066240 -> 281470357092480
	281470357092480 [label=AccumulateGrad]
	281470357092384 -> 281470357092240
	281470644340992 [label="resnet.encoder.stages.0.layers.1.layer.2.convolution.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	281470644340992 -> 281470357092384
	281470357092384 [label=AccumulateGrad]
	281470357092144 -> 281470357092048
	281470644349792 [label="resnet.encoder.stages.0.layers.1.layer.2.normalization.weight
 (256)" fillcolor=lightblue]
	281470644349792 -> 281470357092144
	281470357092144 [label=AccumulateGrad]
	281470357092096 -> 281470357092048
	281470644349952 [label="resnet.encoder.stages.0.layers.1.layer.2.normalization.bias
 (256)" fillcolor=lightblue]
	281470644349952 -> 281470357092096
	281470357092096 [label=AccumulateGrad]
	281470357092000 -> 281470357091952
	281470357091856 -> 281470357091664
	281470644349552 [label="resnet.encoder.stages.0.layers.2.layer.0.convolution.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	281470644349552 -> 281470357091856
	281470357091856 [label=AccumulateGrad]
	281470357091568 -> 281470357091520
	281470644340752 [label="resnet.encoder.stages.0.layers.2.layer.0.normalization.weight
 (64)" fillcolor=lightblue]
	281470644340752 -> 281470357091568
	281470357091568 [label=AccumulateGrad]
	281470357091424 -> 281470357091520
	281470644340832 [label="resnet.encoder.stages.0.layers.2.layer.0.normalization.bias
 (64)" fillcolor=lightblue]
	281470644340832 -> 281470357091424
	281470357091424 [label=AccumulateGrad]
	281470357091280 -> 281470357091136
	281470644340512 [label="resnet.encoder.stages.0.layers.2.layer.1.convolution.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	281470644340512 -> 281470357091280
	281470357091280 [label=AccumulateGrad]
	281470357091040 -> 281470357090992
	281470644349232 [label="resnet.encoder.stages.0.layers.2.layer.1.normalization.weight
 (64)" fillcolor=lightblue]
	281470644349232 -> 281470357091040
	281470357091040 [label=AccumulateGrad]
	281470357090896 -> 281470357090992
	281470644349392 [label="resnet.encoder.stages.0.layers.2.layer.1.normalization.bias
 (64)" fillcolor=lightblue]
	281470644349392 -> 281470357090896
	281470357090896 [label=AccumulateGrad]
	281470357090800 -> 281470357090656
	281470644348912 [label="resnet.encoder.stages.0.layers.2.layer.2.convolution.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	281470644348912 -> 281470357090800
	281470357090800 [label=AccumulateGrad]
	281470357090560 -> 281470357090464
	281470644340192 [label="resnet.encoder.stages.0.layers.2.layer.2.normalization.weight
 (256)" fillcolor=lightblue]
	281470644340192 -> 281470357090560
	281470357090560 [label=AccumulateGrad]
	281470357090512 -> 281470357090464
	281470644339952 [label="resnet.encoder.stages.0.layers.2.layer.2.normalization.bias
 (256)" fillcolor=lightblue]
	281470644339952 -> 281470357090512
	281470357090512 [label=AccumulateGrad]
	281470357090416 -> 281470357090368
	281470357090176 -> 281470357090032
	281470644348752 [label="resnet.encoder.stages.1.layers.0.layer.0.convolution.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	281470644348752 -> 281470357090176
	281470357090176 [label=AccumulateGrad]
	281470357089936 -> 281470357089888
	281470644348672 [label="resnet.encoder.stages.1.layers.0.layer.0.normalization.weight
 (128)" fillcolor=lightblue]
	281470644348672 -> 281470357089936
	281470357089936 [label=AccumulateGrad]
	281470357089792 -> 281470357089888
	281470644339472 [label="resnet.encoder.stages.1.layers.0.layer.0.normalization.bias
 (128)" fillcolor=lightblue]
	281470644339472 -> 281470357089792
	281470357089792 [label=AccumulateGrad]
	281470357089696 -> 281470357089552
	281470644348512 [label="resnet.encoder.stages.1.layers.0.layer.1.convolution.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	281470644348512 -> 281470357089696
	281470357089696 [label=AccumulateGrad]
	281470357089456 -> 281470357089408
	281470644354832 [label="resnet.encoder.stages.1.layers.0.layer.1.normalization.weight
 (128)" fillcolor=lightblue]
	281470644354832 -> 281470357089456
	281470357089456 [label=AccumulateGrad]
	281470357089312 -> 281470357089408
	281470644354912 [label="resnet.encoder.stages.1.layers.0.layer.1.normalization.bias
 (128)" fillcolor=lightblue]
	281470644354912 -> 281470357089312
	281470357089312 [label=AccumulateGrad]
	281470357089216 -> 281470357089072
	281470644348352 [label="resnet.encoder.stages.1.layers.0.layer.2.convolution.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	281470644348352 -> 281470357089216
	281470357089216 [label=AccumulateGrad]
	281470357088976 -> 281470357088880
	281470644338832 [label="resnet.encoder.stages.1.layers.0.layer.2.normalization.weight
 (512)" fillcolor=lightblue]
	281470644338832 -> 281470357088976
	281470357088976 [label=AccumulateGrad]
	281470357088928 -> 281470357088880
	281470644354752 [label="resnet.encoder.stages.1.layers.0.layer.2.normalization.bias
 (512)" fillcolor=lightblue]
	281470644354752 -> 281470357088928
	281470357088928 [label=AccumulateGrad]
	281470357088832 -> 281470357088784
	281470357088832 -> 281470589534832 [dir=none]
	281470589534832 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357088832 -> 281470356781184 [dir=none]
	281470356781184 [label="result1
 (0)" fillcolor=orange]
	281470357088832 -> 281470356782384 [dir=none]
	281470356782384 [label="result2
 (0)" fillcolor=orange]
	281470357088832 -> 281470358016048 [dir=none]
	281470358016048 [label="running_mean
 (512)" fillcolor=orange]
	281470357088832 -> 281470358016368 [dir=none]
	281470358016368 [label="running_var
 (512)" fillcolor=orange]
	281470357088832 -> 281470644339712 [dir=none]
	281470644339712 [label="weight
 (512)" fillcolor=orange]
	281470357088832 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357089648 -> 281470357088832
	281470357089648 -> 281470357807696 [dir=none]
	281470357807696 [label="input
 (1, 256, 56, 56)" fillcolor=orange]
	281470357089648 -> 281470644339632 [dir=none]
	281470644339632 [label="weight
 (512, 256, 1, 1)" fillcolor=orange]
	281470357089648 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470357090224 -> 281470357089648
	281470357090080 -> 281470357089648
	281470644339632 [label="resnet.encoder.stages.1.layers.0.shortcut.convolution.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	281470644339632 -> 281470357090080
	281470357090080 [label=AccumulateGrad]
	281470357089168 -> 281470357088832
	281470644339712 [label="resnet.encoder.stages.1.layers.0.shortcut.normalization.weight
 (512)" fillcolor=lightblue]
	281470644339712 -> 281470357089168
	281470357089168 [label=AccumulateGrad]
	281470357089120 -> 281470357088832
	281470644340272 [label="resnet.encoder.stages.1.layers.0.shortcut.normalization.bias
 (512)" fillcolor=lightblue]
	281470644340272 -> 281470357089120
	281470357089120 [label=AccumulateGrad]
	281470357088688 -> 281470357088496
	281470644354432 [label="resnet.encoder.stages.1.layers.1.layer.0.convolution.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	281470644354432 -> 281470357088688
	281470357088688 [label=AccumulateGrad]
	281470357088400 -> 281470357088352
	281470644354352 [label="resnet.encoder.stages.1.layers.1.layer.0.normalization.weight
 (128)" fillcolor=lightblue]
	281470644354352 -> 281470357088400
	281470357088400 [label=AccumulateGrad]
	281470357088256 -> 281470357088352
	281470644348112 [label="resnet.encoder.stages.1.layers.1.layer.0.normalization.bias
 (128)" fillcolor=lightblue]
	281470644348112 -> 281470357088256
	281470357088256 [label=AccumulateGrad]
	281470357088160 -> 281470357088016
	281470644354112 [label="resnet.encoder.stages.1.layers.1.layer.1.convolution.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	281470644354112 -> 281470357088160
	281470357088160 [label=AccumulateGrad]
	281470357087920 -> 281470357087872
	281470644354032 [label="resnet.encoder.stages.1.layers.1.layer.1.normalization.weight
 (128)" fillcolor=lightblue]
	281470644354032 -> 281470357087920
	281470357087920 [label=AccumulateGrad]
	281470357087776 -> 281470357087872
	281470644347792 [label="resnet.encoder.stages.1.layers.1.layer.1.normalization.bias
 (128)" fillcolor=lightblue]
	281470644347792 -> 281470357087776
	281470357087776 [label=AccumulateGrad]
	281470357087680 -> 281470357087536
	281470644353792 [label="resnet.encoder.stages.1.layers.1.layer.2.convolution.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	281470644353792 -> 281470357087680
	281470357087680 [label=AccumulateGrad]
	281470357087440 -> 281470357087344
	281470644347312 [label="resnet.encoder.stages.1.layers.1.layer.2.normalization.weight
 (512)" fillcolor=lightblue]
	281470644347312 -> 281470357087440
	281470357087440 [label=AccumulateGrad]
	281470357087392 -> 281470357087344
	281470644347472 [label="resnet.encoder.stages.1.layers.1.layer.2.normalization.bias
 (512)" fillcolor=lightblue]
	281470644347472 -> 281470357087392
	281470357087392 [label=AccumulateGrad]
	281470357087296 -> 281470357087248
	281470357087152 -> 281470357086960
	281470644353552 [label="resnet.encoder.stages.1.layers.2.layer.0.convolution.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	281470644353552 -> 281470357087152
	281470357087152 [label=AccumulateGrad]
	281470357086864 -> 281470357086816
	281470644347072 [label="resnet.encoder.stages.1.layers.2.layer.0.normalization.weight
 (128)" fillcolor=lightblue]
	281470644347072 -> 281470357086864
	281470357086864 [label=AccumulateGrad]
	281470357086720 -> 281470357086816
	281470644347232 [label="resnet.encoder.stages.1.layers.2.layer.0.normalization.bias
 (128)" fillcolor=lightblue]
	281470644347232 -> 281470357086720
	281470357086720 [label=AccumulateGrad]
	281470357086624 -> 281470357086480
	281470644346672 [label="resnet.encoder.stages.1.layers.2.layer.1.convolution.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	281470644346672 -> 281470357086624
	281470357086624 [label=AccumulateGrad]
	281470357086384 -> 281470357086336
	281470644346912 [label="resnet.encoder.stages.1.layers.2.layer.1.normalization.weight
 (128)" fillcolor=lightblue]
	281470644346912 -> 281470357086384
	281470357086384 [label=AccumulateGrad]
	281470357086240 -> 281470357086336
	281470644353152 [label="resnet.encoder.stages.1.layers.2.layer.1.normalization.bias
 (128)" fillcolor=lightblue]
	281470644353152 -> 281470357086240
	281470357086240 [label=AccumulateGrad]
	281470357086144 -> 281470357086000
	281470644346512 [label="resnet.encoder.stages.1.layers.2.layer.2.convolution.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	281470644346512 -> 281470357086144
	281470357086144 [label=AccumulateGrad]
	281470357085904 -> 281470357085808
	281470644352832 [label="resnet.encoder.stages.1.layers.2.layer.2.normalization.weight
 (512)" fillcolor=lightblue]
	281470644352832 -> 281470357085904
	281470357085904 [label=AccumulateGrad]
	281470357085856 -> 281470357085808
	281470644352992 [label="resnet.encoder.stages.1.layers.2.layer.2.normalization.bias
 (512)" fillcolor=lightblue]
	281470644352992 -> 281470357085856
	281470357085856 [label=AccumulateGrad]
	281470357085760 -> 281470357085712
	281470357085616 -> 281470357085424
	281470644346272 [label="resnet.encoder.stages.1.layers.3.layer.0.convolution.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	281470644346272 -> 281470357085616
	281470357085616 [label=AccumulateGrad]
	281470357085328 -> 281470357085280
	281470644352512 [label="resnet.encoder.stages.1.layers.3.layer.0.normalization.weight
 (128)" fillcolor=lightblue]
	281470644352512 -> 281470357085328
	281470357085328 [label=AccumulateGrad]
	281470357085184 -> 281470357085280
	281470644352752 [label="resnet.encoder.stages.1.layers.3.layer.0.normalization.bias
 (128)" fillcolor=lightblue]
	281470644352752 -> 281470357085184
	281470357085184 [label=AccumulateGrad]
	281470357085088 -> 281470357084944
	281470644345792 [label="resnet.encoder.stages.1.layers.3.layer.1.convolution.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	281470644345792 -> 281470357085088
	281470357085088 [label=AccumulateGrad]
	281470357084848 -> 281470357084800
	281470644352032 [label="resnet.encoder.stages.1.layers.3.layer.1.normalization.weight
 (128)" fillcolor=lightblue]
	281470644352032 -> 281470357084848
	281470357084848 [label=AccumulateGrad]
	281470357084704 -> 281470357084800
	281470644352272 [label="resnet.encoder.stages.1.layers.3.layer.1.normalization.bias
 (128)" fillcolor=lightblue]
	281470644352272 -> 281470357084704
	281470357084704 [label=AccumulateGrad]
	281470357084608 -> 281470357084464
	281470358062160 [label="resnet.encoder.stages.1.layers.3.layer.2.convolution.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	281470358062160 -> 281470357084608
	281470357084608 [label=AccumulateGrad]
	281470357084368 -> 281470357084272
	281470644351792 [label="resnet.encoder.stages.1.layers.3.layer.2.normalization.weight
 (512)" fillcolor=lightblue]
	281470644351792 -> 281470357084368
	281470357084368 [label=AccumulateGrad]
	281470357084320 -> 281470357084272
	281470644351952 [label="resnet.encoder.stages.1.layers.3.layer.2.normalization.bias
 (512)" fillcolor=lightblue]
	281470644351952 -> 281470357084320
	281470357084320 [label=AccumulateGrad]
	281470357084224 -> 281470357084176
	281470357083984 -> 281470357083840
	281470644344912 [label="resnet.encoder.stages.2.layers.0.layer.0.convolution.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	281470644344912 -> 281470357083984
	281470357083984 [label=AccumulateGrad]
	281470357083744 -> 281470357083696
	281470644352352 [label="resnet.encoder.stages.2.layers.0.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470644352352 -> 281470357083744
	281470357083744 [label=AccumulateGrad]
	281470357083600 -> 281470357083696
	281470644345072 [label="resnet.encoder.stages.2.layers.0.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470644345072 -> 281470357083600
	281470357083600 [label=AccumulateGrad]
	281470357083504 -> 281470357083360
	281470644350512 [label="resnet.encoder.stages.2.layers.0.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470644350512 -> 281470357083504
	281470357083504 [label=AccumulateGrad]
	281470357083264 -> 281470357083216
	281470358160544 [label="resnet.encoder.stages.2.layers.0.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358160544 -> 281470357083264
	281470357083264 [label=AccumulateGrad]
	281470357083120 -> 281470357083216
	281470644345872 [label="resnet.encoder.stages.2.layers.0.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470644345872 -> 281470357083120
	281470357083120 [label=AccumulateGrad]
	281470357083024 -> 281470357082880
	281470358161024 [label="resnet.encoder.stages.2.layers.0.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358161024 -> 281470357083024
	281470357083024 [label=AccumulateGrad]
	281470357082784 -> 281470357082688
	281470358161184 [label="resnet.encoder.stages.2.layers.0.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358161184 -> 281470357082784
	281470357082784 [label=AccumulateGrad]
	281470357082736 -> 281470357082688
	281470358160704 [label="resnet.encoder.stages.2.layers.0.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358160704 -> 281470357082736
	281470357082736 [label=AccumulateGrad]
	281470357082640 -> 281470357082592
	281470357082640 -> 281470358071360 [dir=none]
	281470358071360 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470357082640 -> 281470356781424 [dir=none]
	281470356781424 [label="result1
 (0)" fillcolor=orange]
	281470357082640 -> 281470356780864 [dir=none]
	281470356780864 [label="result2
 (0)" fillcolor=orange]
	281470357082640 -> 281470358057296 [dir=none]
	281470358057296 [label="running_mean
 (1024)" fillcolor=orange]
	281470357082640 -> 281470358057616 [dir=none]
	281470358057616 [label="running_var
 (1024)" fillcolor=orange]
	281470357082640 -> 281470644351472 [dir=none]
	281470644351472 [label="weight
 (1024)" fillcolor=orange]
	281470357082640 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470357083456 -> 281470357082640
	281470357083456 -> 281470358073280 [dir=none]
	281470358073280 [label="input
 (1, 512, 28, 28)" fillcolor=orange]
	281470357083456 -> 281470358098528 [dir=none]
	281470358098528 [label="weight
 (1024, 512, 1, 1)" fillcolor=orange]
	281470357083456 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470357084032 -> 281470357083456
	281470357083888 -> 281470357083456
	281470358098528 [label="resnet.encoder.stages.2.layers.0.shortcut.convolution.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	281470358098528 -> 281470357083888
	281470357083888 [label=AccumulateGrad]
	281470357082976 -> 281470357082640
	281470644351472 [label="resnet.encoder.stages.2.layers.0.shortcut.normalization.weight
 (1024)" fillcolor=lightblue]
	281470644351472 -> 281470357082976
	281470357082976 [label=AccumulateGrad]
	281470357082928 -> 281470357082640
	281470644351552 [label="resnet.encoder.stages.2.layers.0.shortcut.normalization.bias
 (1024)" fillcolor=lightblue]
	281470644351552 -> 281470357082928
	281470357082928 [label=AccumulateGrad]
	281470357082496 -> 281470357082304
	281470358161584 [label="resnet.encoder.stages.2.layers.1.layer.0.convolution.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	281470358161584 -> 281470357082496
	281470357082496 [label=AccumulateGrad]
	281470357082208 -> 281470357082160
	281470358161744 [label="resnet.encoder.stages.2.layers.1.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470358161744 -> 281470357082208
	281470357082208 [label=AccumulateGrad]
	281470357082064 -> 281470357082160
	281470358161344 [label="resnet.encoder.stages.2.layers.1.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470358161344 -> 281470357082064
	281470357082064 [label=AccumulateGrad]
	281470357081728 -> 281470356348912
	281470358162224 [label="resnet.encoder.stages.2.layers.1.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470358162224 -> 281470357081728
	281470357081728 [label=AccumulateGrad]
	281470356348864 -> 281470357081824
	281470358162384 [label="resnet.encoder.stages.2.layers.1.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358162384 -> 281470356348864
	281470356348864 [label=AccumulateGrad]
	281470356348960 -> 281470357081824
	281470358161904 [label="resnet.encoder.stages.2.layers.1.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470358161904 -> 281470356348960
	281470356348960 [label=AccumulateGrad]
	281470357081632 -> 281470357081488
	281470358162864 [label="resnet.encoder.stages.2.layers.1.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358162864 -> 281470357081632
	281470357081632 [label=AccumulateGrad]
	281470357081392 -> 281470357081296
	281470358163024 [label="resnet.encoder.stages.2.layers.1.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358163024 -> 281470357081392
	281470357081392 [label=AccumulateGrad]
	281470357081344 -> 281470357081296
	281470358162544 [label="resnet.encoder.stages.2.layers.1.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358162544 -> 281470357081344
	281470357081344 [label=AccumulateGrad]
	281470357081248 -> 281470357081200
	281470357081104 -> 281470357080912
	281470358163504 [label="resnet.encoder.stages.2.layers.2.layer.0.convolution.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	281470358163504 -> 281470357081104
	281470357081104 [label=AccumulateGrad]
	281470357080816 -> 281470357080768
	281470358163664 [label="resnet.encoder.stages.2.layers.2.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470358163664 -> 281470357080816
	281470357080816 [label=AccumulateGrad]
	281470357080672 -> 281470357080768
	281470358163184 [label="resnet.encoder.stages.2.layers.2.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470358163184 -> 281470357080672
	281470357080672 [label=AccumulateGrad]
	281470357080576 -> 281470357080432
	281470358164064 [label="resnet.encoder.stages.2.layers.2.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470358164064 -> 281470357080576
	281470357080576 [label=AccumulateGrad]
	281470357080336 -> 281470357080288
	281470358164224 [label="resnet.encoder.stages.2.layers.2.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358164224 -> 281470357080336
	281470357080336 [label=AccumulateGrad]
	281470357080192 -> 281470357080288
	281470358163744 [label="resnet.encoder.stages.2.layers.2.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470358163744 -> 281470357080192
	281470357080192 [label=AccumulateGrad]
	281470357080096 -> 281470357079952
	281470358164704 [label="resnet.encoder.stages.2.layers.2.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358164704 -> 281470357080096
	281470357080096 [label=AccumulateGrad]
	281470357079856 -> 281470357079760
	281470358164864 [label="resnet.encoder.stages.2.layers.2.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358164864 -> 281470357079856
	281470357079856 [label=AccumulateGrad]
	281470357079808 -> 281470357079760
	281470358164384 [label="resnet.encoder.stages.2.layers.2.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358164384 -> 281470357079808
	281470357079808 [label=AccumulateGrad]
	281470357079712 -> 281470357079664
	281470357079568 -> 281470357079376
	281470358165344 [label="resnet.encoder.stages.2.layers.3.layer.0.convolution.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	281470358165344 -> 281470357079568
	281470357079568 [label=AccumulateGrad]
	281470357079328 -> 281470357079280
	281470358165504 [label="resnet.encoder.stages.2.layers.3.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470358165504 -> 281470357079328
	281470357079328 [label=AccumulateGrad]
	281470357079184 -> 281470357079280
	281470358165024 [label="resnet.encoder.stages.2.layers.3.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470358165024 -> 281470357079184
	281470357079184 [label=AccumulateGrad]
	281470357079088 -> 281470357078944
	281470358165984 [label="resnet.encoder.stages.2.layers.3.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470358165984 -> 281470357079088
	281470357079088 [label=AccumulateGrad]
	281470357078896 -> 281470357078848
	281470358166144 [label="resnet.encoder.stages.2.layers.3.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358166144 -> 281470357078896
	281470357078896 [label=AccumulateGrad]
	281470357078752 -> 281470357078848
	281470358165664 [label="resnet.encoder.stages.2.layers.3.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470358165664 -> 281470357078752
	281470357078752 [label=AccumulateGrad]
	281470357078656 -> 281470357078512
	281470358166624 [label="resnet.encoder.stages.2.layers.3.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358166624 -> 281470357078656
	281470357078656 [label=AccumulateGrad]
	281470357078464 -> 281470357078368
	281470358166784 [label="resnet.encoder.stages.2.layers.3.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358166784 -> 281470357078464
	281470357078464 [label=AccumulateGrad]
	281470357078416 -> 281470357078368
	281470358166304 [label="resnet.encoder.stages.2.layers.3.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358166304 -> 281470357078416
	281470357078416 [label=AccumulateGrad]
	281470357078320 -> 281470357078272
	281470357078176 -> 281470356357024
	281470358167264 [label="resnet.encoder.stages.2.layers.4.layer.0.convolution.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	281470358167264 -> 281470357078176
	281470357078176 [label=AccumulateGrad]
	281470356356976 -> 281470356356928
	281470358167424 [label="resnet.encoder.stages.2.layers.4.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470358167424 -> 281470356356976
	281470356356976 [label=AccumulateGrad]
	281470356356832 -> 281470356356928
	281470358166944 [label="resnet.encoder.stages.2.layers.4.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470358166944 -> 281470356356832
	281470356356832 [label=AccumulateGrad]
	281470356356736 -> 281470356356592
	281470358167904 [label="resnet.encoder.stages.2.layers.4.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470358167904 -> 281470356356736
	281470356356736 [label=AccumulateGrad]
	281470356356544 -> 281470356356496
	281470358168224 [label="resnet.encoder.stages.2.layers.4.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358168224 -> 281470356356544
	281470356356544 [label=AccumulateGrad]
	281470356356400 -> 281470356356496
	281470358167584 [label="resnet.encoder.stages.2.layers.4.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470358167584 -> 281470356356400
	281470356356400 [label=AccumulateGrad]
	281470356356304 -> 281470356356160
	281470358168624 [label="resnet.encoder.stages.2.layers.4.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358168624 -> 281470356356304
	281470356356304 [label=AccumulateGrad]
	281470356356112 -> 281470356356016
	281470358168864 [label="resnet.encoder.stages.2.layers.4.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358168864 -> 281470356356112
	281470356356112 [label=AccumulateGrad]
	281470356356064 -> 281470356356016
	281470358168464 [label="resnet.encoder.stages.2.layers.4.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358168464 -> 281470356356064
	281470356356064 [label=AccumulateGrad]
	281470356355968 -> 281470356355920
	281470356355824 -> 281470356355632
	281470358169264 [label="resnet.encoder.stages.2.layers.5.layer.0.convolution.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	281470358169264 -> 281470356355824
	281470356355824 [label=AccumulateGrad]
	281470356355536 -> 281470356355488
	281470358169424 [label="resnet.encoder.stages.2.layers.5.layer.0.normalization.weight
 (256)" fillcolor=lightblue]
	281470358169424 -> 281470356355536
	281470356355536 [label=AccumulateGrad]
	281470356355392 -> 281470356355488
	281470358169104 [label="resnet.encoder.stages.2.layers.5.layer.0.normalization.bias
 (256)" fillcolor=lightblue]
	281470358169104 -> 281470356355392
	281470356355392 [label=AccumulateGrad]
	281470356355296 -> 281470356355152
	281470358169824 [label="resnet.encoder.stages.2.layers.5.layer.1.convolution.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	281470358169824 -> 281470356355296
	281470356355296 [label=AccumulateGrad]
	281470356355104 -> 281470356355056
	281470358170064 [label="resnet.encoder.stages.2.layers.5.layer.1.normalization.weight
 (256)" fillcolor=lightblue]
	281470358170064 -> 281470356355104
	281470356355104 [label=AccumulateGrad]
	281470356354960 -> 281470356355056
	281470358169664 [label="resnet.encoder.stages.2.layers.5.layer.1.normalization.bias
 (256)" fillcolor=lightblue]
	281470358169664 -> 281470356354960
	281470356354960 [label=AccumulateGrad]
	281470356354864 -> 281470356354720
	281470358170464 [label="resnet.encoder.stages.2.layers.5.layer.2.convolution.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	281470358170464 -> 281470356354864
	281470356354864 [label=AccumulateGrad]
	281470356354672 -> 281470356354576
	281470358170704 [label="resnet.encoder.stages.2.layers.5.layer.2.normalization.weight
 (1024)" fillcolor=lightblue]
	281470358170704 -> 281470356354672
	281470356354672 [label=AccumulateGrad]
	281470356354624 -> 281470356354576
	281470358170304 [label="resnet.encoder.stages.2.layers.5.layer.2.normalization.bias
 (1024)" fillcolor=lightblue]
	281470358170304 -> 281470356354624
	281470356354624 [label=AccumulateGrad]
	281470356354528 -> 281470356354480
	281470356354288 -> 281470356354144
	281470358171344 [label="resnet.encoder.stages.3.layers.0.layer.0.convolution.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	281470358171344 -> 281470356354288
	281470356354288 [label=AccumulateGrad]
	281470356354096 -> 281470356354048
	281470358171504 [label="resnet.encoder.stages.3.layers.0.layer.0.normalization.weight
 (512)" fillcolor=lightblue]
	281470358171504 -> 281470356354096
	281470356354096 [label=AccumulateGrad]
	281470356353952 -> 281470356354048
	281470358170944 [label="resnet.encoder.stages.3.layers.0.layer.0.normalization.bias
 (512)" fillcolor=lightblue]
	281470358170944 -> 281470356353952
	281470356353952 [label=AccumulateGrad]
	281470356353856 -> 281470356353712
	281470358171984 [label="resnet.encoder.stages.3.layers.0.layer.1.convolution.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	281470358171984 -> 281470356353856
	281470356353856 [label=AccumulateGrad]
	281470356353664 -> 281470356353616
	281470358172144 [label="resnet.encoder.stages.3.layers.0.layer.1.normalization.weight
 (512)" fillcolor=lightblue]
	281470358172144 -> 281470356353664
	281470356353664 [label=AccumulateGrad]
	281470356353520 -> 281470356353616
	281470358171664 [label="resnet.encoder.stages.3.layers.0.layer.1.normalization.bias
 (512)" fillcolor=lightblue]
	281470358171664 -> 281470356353520
	281470356353520 [label=AccumulateGrad]
	281470356353424 -> 281470356353280
	281470358172544 [label="resnet.encoder.stages.3.layers.0.layer.2.convolution.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	281470358172544 -> 281470356353424
	281470356353424 [label=AccumulateGrad]
	281470356353232 -> 281470356353136
	281470358172704 [label="resnet.encoder.stages.3.layers.0.layer.2.normalization.weight
 (2048)" fillcolor=lightblue]
	281470358172704 -> 281470356353232
	281470356353232 [label=AccumulateGrad]
	281470356353184 -> 281470356353136
	281470358172064 [label="resnet.encoder.stages.3.layers.0.layer.2.normalization.bias
 (2048)" fillcolor=lightblue]
	281470358172064 -> 281470356353184
	281470356353184 [label=AccumulateGrad]
	281470356353088 -> 281470356353040
	281470356353088 -> 281470358093664 [dir=none]
	281470358093664 [label="input
 (1, 2048, 7, 7)" fillcolor=orange]
	281470356353088 -> 281470356780704 [dir=none]
	281470356780704 [label="result1
 (0)" fillcolor=orange]
	281470356353088 -> 281470356781104 [dir=none]
	281470356781104 [label="result2
 (0)" fillcolor=orange]
	281470356353088 -> 281470358093024 [dir=none]
	281470358093024 [label="running_mean
 (2048)" fillcolor=orange]
	281470356353088 -> 281470358093344 [dir=none]
	281470358093344 [label="running_var
 (2048)" fillcolor=orange]
	281470356353088 -> 281470358171184 [dir=none]
	281470358171184 [label="weight
 (2048)" fillcolor=orange]
	281470356353088 [label="NativeBatchNormBackward0
----------------------------
eps         :          1e-05
input       : [saved tensor]
result1     : [saved tensor]
result2     : [saved tensor]
running_mean: [saved tensor]
running_var : [saved tensor]
training    :          False
weight      : [saved tensor]"]
	281470356353808 -> 281470356353088
	281470356353808 -> 281470358062080 [dir=none]
	281470358062080 [label="input
 (1, 1024, 14, 14)" fillcolor=orange]
	281470356353808 -> 281470358162944 [dir=none]
	281470358162944 [label="weight
 (2048, 1024, 1, 1)" fillcolor=orange]
	281470356353808 [label="ConvolutionBackward0
----------------------------------
bias_sym_sizes_opt:           (0,)
dilation          :         (1, 1)
groups            :              1
input             : [saved tensor]
output_padding    :         (0, 0)
padding           :         (0, 0)
stride            :         (2, 2)
transposed        :          False
weight            : [saved tensor]"]
	281470356354336 -> 281470356353808
	281470356354192 -> 281470356353808
	281470358162944 [label="resnet.encoder.stages.3.layers.0.shortcut.convolution.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	281470358162944 -> 281470356354192
	281470356354192 [label=AccumulateGrad]
	281470356353376 -> 281470356353088
	281470358171184 [label="resnet.encoder.stages.3.layers.0.shortcut.normalization.weight
 (2048)" fillcolor=lightblue]
	281470358171184 -> 281470356353376
	281470356353376 [label=AccumulateGrad]
	281470356353328 -> 281470356353088
	281470358171024 [label="resnet.encoder.stages.3.layers.0.shortcut.normalization.bias
 (2048)" fillcolor=lightblue]
	281470358171024 -> 281470356353328
	281470356353328 [label=AccumulateGrad]
	281470356352944 -> 281470356352752
	281470358173104 [label="resnet.encoder.stages.3.layers.1.layer.0.convolution.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	281470358173104 -> 281470356352944
	281470356352944 [label=AccumulateGrad]
	281470356352704 -> 281470356352656
	281470358173264 [label="resnet.encoder.stages.3.layers.1.layer.0.normalization.weight
 (512)" fillcolor=lightblue]
	281470358173264 -> 281470356352704
	281470356352704 [label=AccumulateGrad]
	281470356352560 -> 281470356352656
	281470358172784 [label="resnet.encoder.stages.3.layers.1.layer.0.normalization.bias
 (512)" fillcolor=lightblue]
	281470358172784 -> 281470356352560
	281470356352560 [label=AccumulateGrad]
	281470356352464 -> 281470356352320
	281470358173664 [label="resnet.encoder.stages.3.layers.1.layer.1.convolution.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	281470358173664 -> 281470356352464
	281470356352464 [label=AccumulateGrad]
	281470356352272 -> 281470356352224
	281470358173824 [label="resnet.encoder.stages.3.layers.1.layer.1.normalization.weight
 (512)" fillcolor=lightblue]
	281470358173824 -> 281470356352272
	281470356352272 [label=AccumulateGrad]
	281470356352128 -> 281470356352224
	281470358173344 [label="resnet.encoder.stages.3.layers.1.layer.1.normalization.bias
 (512)" fillcolor=lightblue]
	281470358173344 -> 281470356352128
	281470356352128 [label=AccumulateGrad]
	281470356352032 -> 281470356351888
	281470358174304 [label="resnet.encoder.stages.3.layers.1.layer.2.convolution.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	281470358174304 -> 281470356352032
	281470356352032 [label=AccumulateGrad]
	281470356351840 -> 281470356351744
	281470358174464 [label="resnet.encoder.stages.3.layers.1.layer.2.normalization.weight
 (2048)" fillcolor=lightblue]
	281470358174464 -> 281470356351840
	281470356351840 [label=AccumulateGrad]
	281470356351792 -> 281470356351744
	281470358173984 [label="resnet.encoder.stages.3.layers.1.layer.2.normalization.bias
 (2048)" fillcolor=lightblue]
	281470358173984 -> 281470356351792
	281470356351792 [label=AccumulateGrad]
	281470356351696 -> 281470356351648
	281470356351552 -> 281470356351360
	281470358174624 [label="resnet.encoder.stages.3.layers.2.layer.0.convolution.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	281470358174624 -> 281470356351552
	281470356351552 [label=AccumulateGrad]
	281470356351312 -> 281470356351264
	281470358174944 [label="resnet.encoder.stages.3.layers.2.layer.0.normalization.weight
 (512)" fillcolor=lightblue]
	281470358174944 -> 281470356351312
	281470356351312 [label=AccumulateGrad]
	281470356351168 -> 281470356351264
	281470358174864 [label="resnet.encoder.stages.3.layers.2.layer.0.normalization.bias
 (512)" fillcolor=lightblue]
	281470358174864 -> 281470356351168
	281470356351168 [label=AccumulateGrad]
	281470356351072 -> 281470356350928
	281470358175504 [label="resnet.encoder.stages.3.layers.2.layer.1.convolution.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	281470358175504 -> 281470356351072
	281470356351072 [label=AccumulateGrad]
	281470356350880 -> 281470356350832
	281470358175664 [label="resnet.encoder.stages.3.layers.2.layer.1.normalization.weight
 (512)" fillcolor=lightblue]
	281470358175664 -> 281470356350880
	281470356350880 [label=AccumulateGrad]
	281470356350736 -> 281470356350832
	281470358175184 [label="resnet.encoder.stages.3.layers.2.layer.1.normalization.bias
 (512)" fillcolor=lightblue]
	281470358175184 -> 281470356350736
	281470356350736 [label=AccumulateGrad]
	281470356350640 -> 281470356350496
	281470356767184 [label="resnet.encoder.stages.3.layers.2.layer.2.convolution.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	281470356767184 -> 281470356350640
	281470356350640 [label=AccumulateGrad]
	281470356350448 -> 281470356350352
	281470356767504 [label="resnet.encoder.stages.3.layers.2.layer.2.normalization.weight
 (2048)" fillcolor=lightblue]
	281470356767504 -> 281470356350448
	281470356350448 [label=AccumulateGrad]
	281470356350400 -> 281470356350352
	281470356766864 [label="resnet.encoder.stages.3.layers.2.layer.2.normalization.bias
 (2048)" fillcolor=lightblue]
	281470356766864 -> 281470356350400
	281470356350400 [label=AccumulateGrad]
	281470356350304 -> 281470356350256
	281470356349728 -> 281470356349200
	281470356349728 [label=TBackward0]
	281470356350208 -> 281470356349728
	281470581864416 [label="classifier.1.weight
 (1000, 2048)" fillcolor=lightblue]
	281470581864416 -> 281470356350208
	281470356350208 [label=AccumulateGrad]
	281470356349200 -> 281470358086784
}
